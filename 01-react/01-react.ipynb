{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6cf5f45",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tiagodsilva/llm-programs/blob/main/01-react/01-react.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b561629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Bootstrap (click to expand)\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Running in Colab â€” installing dependencies...\")\n",
    "    \n",
    "    # Fetch pyproject.toml\n",
    "    !curl -L -o pyproject.toml https://raw.githubusercontent.com/tiagodsilva/llm-programs/main/requirements.txt\n",
    "    \n",
    "    # Install poetry and dependencies\n",
    "    %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f8b323",
   "metadata": {},
   "source": [
    "## Connect to the LLM provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2359dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "\n",
    "def _set_if_undefined(var: str) -> None:\n",
    "    if os.environ.get(var):\n",
    "        return\n",
    "    os.environ[var] = getpass(var)\n",
    "\n",
    "\n",
    "_set_if_undefined(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d97ec357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4.1-mini\",\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d405547a",
   "metadata": {},
   "source": [
    "## Creating a stock database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d9e90f",
   "metadata": {},
   "source": [
    "We will create an in-memory SQLite database for illustration purposes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a00ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import MetaData\n",
    "\n",
    "metadata_obj = MetaData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ea5b209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import Column, Integer, String, Table, Date, Float\n",
    "\n",
    "stocks = Table(\n",
    "    \"stocks\",\n",
    "    metadata_obj,\n",
    "    Column(\"obs_id\", Integer, primary_key=True),\n",
    "    Column(\"stock_ticker\", String(4), nullable=False),\n",
    "    Column(\"price\", Float, nullable=False),\n",
    "    Column(\"date\", Date, nullable=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7eb8968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "database_file = \"temp_stocks_db.db\"\n",
    "\n",
    "if os.path.exists(database_file):\n",
    "    os.remove(database_file)\n",
    "\n",
    "engine = create_engine(\n",
    "    f\"sqlite:///{database_file}\", connect_args={\"check_same_thread\": False}\n",
    ")\n",
    "metadata_obj.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50d52b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "observations = [\n",
    "    [1, \"ABC\", 200, datetime(2023, 1, 1)],\n",
    "    [2, \"ABC\", 208, datetime(2023, 1, 2)],\n",
    "    [3, \"ABC\", 232, datetime(2023, 1, 3)],\n",
    "    [4, \"ABC\", 225, datetime(2023, 1, 4)],\n",
    "    [5, \"ABC\", 226, datetime(2023, 1, 5)],\n",
    "    [6, \"XYZ\", 810, datetime(2023, 1, 1)],\n",
    "    [7, \"XYZ\", 803, datetime(2023, 1, 2)],\n",
    "    [8, \"XYZ\", 798, datetime(2023, 1, 3)],\n",
    "    [9, \"XYZ\", 795, datetime(2023, 1, 4)],\n",
    "    [10, \"XYZ\", 791, datetime(2023, 1, 5)],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1d9302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import insert\n",
    "\n",
    "\n",
    "def insert_obs(obs):\n",
    "    stmt = insert(stocks).values(\n",
    "        obs_id=obs[0],\n",
    "        stock_ticker=obs[1],\n",
    "        price=obs[2],\n",
    "        date=obs[3],\n",
    "    )\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(stmt)\n",
    "\n",
    "\n",
    "for obs in observations:\n",
    "    insert_obs(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3be9191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "db = SQLDatabase(engine=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac9a962",
   "metadata": {},
   "source": [
    "## Creating the SQL agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20148be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an agent designed to interact with a SQL database.\n",
    "Given an input question, create a syntactically correct {dialect} query to run,\n",
    "then look at the results of the query and return the answer. Unless the user\n",
    "specifies a specific number of examples they wish to obtain, always limit your\n",
    "query to at most {top_k} results.\n",
    "\n",
    "You can order the results by a relevant column to return the most interesting\n",
    "examples in the database. Never query for all the columns from a specific table,\n",
    "only ask for the relevant columns given the question.\n",
    "\n",
    "You MUST double check your query before executing it. If you get an error while\n",
    "executing a query, rewrite the query and try again.\n",
    "\n",
    "DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the\n",
    "database.\n",
    "\n",
    "To start you should ALWAYS look at the tables in the database to see what you\n",
    "can query. Do NOT skip this step.\n",
    "\n",
    "Then you should query the schema of the most relevant tables.\n",
    "\"\"\".format(\n",
    "    dialect=db.dialect,\n",
    "    top_k=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d24b2ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "db = SQLDatabase(engine=engine, include_tables=[\"stocks\"])\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=toolkit.get_tools(),\n",
    "    system_prompt=system_prompt,\n",
    "    # debug=True, Set debug=True to inspect the LLM reasoning.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1f5a613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stocks']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.get_usable_table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec6ba944",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "    \"What is the multiplication of the ratio between stock \"\n",
    "    \"prices for 'ABC' and 'XYZ' in January 3rd and the ratio \"\n",
    "    \"between the same stock prices in January the 4th?\"\n",
    ")\n",
    "\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fab59cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prices for 'ABC' and 'XYZ' on January 3rd are 232.0 and 798.0 respectively.\n",
      "The prices for 'ABC' and 'XYZ' on January 4th are 225.0 and 795.0 respectively.\n",
      "\n",
      "Now, let's calculate the multiplication of the ratio between stock prices for 'ABC' and 'XYZ' on January 3rd and the ratio between the same stock prices on January 4th:\n",
      "\n",
      "Ratio on January 3rd = 232.0 / 798.0\n",
      "Ratio on January 4th = 225.0 / 795.0\n",
      "\n",
      "Multiplication of the two ratios = (232.0 / 798.0) * (225.0 / 795.0) = 0.0823 (approximately).\n"
     ]
    }
   ],
   "source": [
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02c6825",
   "metadata": {},
   "source": [
    "## Conversational agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13075e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "import math\n",
    "import numexpr\n",
    "\n",
    "\n",
    "@tool  # Docstrings are REQUIRED for tools\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Calculate expression using Python's numexpr library.\n",
    "\n",
    "    Examples:\n",
    "        \"37593 * 67\" for \"37593 times 67\"\n",
    "        \"37593**(1/5)\" for \"37593^(1/5)\"\n",
    "    \"\"\"\n",
    "    local_dict = {\"pi\": math.pi, \"e\": math.e}\n",
    "    return str(\n",
    "        numexpr.evaluate(\n",
    "            expression.strip(),\n",
    "            global_dict={},  # restrict access to globals\n",
    "            local_dict=local_dict,  # add common mathematical functions\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bc485c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def final_answer(answer: str, tools_used: list[str]) -> str:\n",
    "    \"\"\"Use this tool to provide a final answer to the user.\n",
    "    The answer should be in natural language as this will be provided\n",
    "    to the user directly. The tools_used must include a list of tool\n",
    "    names that were used within the `scratchpad`.\n",
    "    \"\"\"\n",
    "    return {\"answer\": answer, \"tools_used\": tools_used}\n",
    "\n",
    "\n",
    "# Add tools\n",
    "tools = [final_answer, calculator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abc9f41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.base import RunnableSerializable\n",
    "\n",
    "# First, create a prompt that forces the LLM to analyze the history\n",
    "history_analysis_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            (\n",
    "                \"Analyze the conversation history below and identify any calculations that have already been performed. \"\n",
    "                \"Extract the results of these calculations so they can be reused instead of recalculating.\"\n",
    "            ),\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"What calculations have been done and what are their results?\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Then the main agent prompt\n",
    "agent_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            (\n",
    "                \"You're a helpful assistant. When answering a user's question \"\n",
    "                \"you should first use one of the tools provided. After using a \"\n",
    "                \"tool the tool output will be provided in the \"\n",
    "                \"'scratchpad' below. If you have an answer in the \"\n",
    "                \"scratchpad you should not use any more tools and \"\n",
    "                \"instead answer directly to the user. \"\n",
    "                \"IMPORTANT: Use the analysis of previous calculations to avoid recalculating.\"\n",
    "            ),\n",
    "        ),\n",
    "        (\"human\", \"Previous calculations analysis: {history_analysis}\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# define the agent runnable with history analysis first\n",
    "agent: RunnableSerializable = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", []),\n",
    "    }\n",
    "    | {\n",
    "        \"history_analysis\": lambda x: llm.invoke(\n",
    "            history_analysis_prompt.format_messages(chat_history=x[\"chat_history\"])\n",
    "        ).content,\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", []),\n",
    "    }\n",
    "    | agent_prompt\n",
    "    | llm.bind_tools(tools, tool_choice=\"auto\")\n",
    ")\n",
    "\n",
    "# create tool name to function mapping as per guide\n",
    "name2tool = {tool.name: tool.func for tool in tools}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd06abcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "\n",
    "\n",
    "class CustomAgentExecutor:\n",
    "    def __init__(self, max_iterations: int = 5):\n",
    "        self.max_iterations = max_iterations\n",
    "        self.memory = (\n",
    "            InMemoryChatMessageHistory()\n",
    "        )  # Simple in-memory structure to store conversation history\n",
    "        self.agent = agent\n",
    "\n",
    "    def invoke(self, input: str) -> dict:\n",
    "        # invoke the agent but we do this iteratively in a loop until\n",
    "        # reaching a final answer\n",
    "        count = 0\n",
    "        agent_scratchpad = []\n",
    "\n",
    "        while count < self.max_iterations:\n",
    "            # invoke a step for the agent to generate a tool call\n",
    "            response = self.agent.invoke(\n",
    "                {\n",
    "                    \"input\": input,\n",
    "                    \"chat_history\": self.memory.messages,\n",
    "                    \"agent_scratchpad\": agent_scratchpad,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # add initial tool call to scratchpad\n",
    "            agent_scratchpad.append(response)\n",
    "\n",
    "            # Handle ALL tool calls, not just the first one\n",
    "            if response.tool_calls:\n",
    "                for tool_call_obj in response.tool_calls:\n",
    "                    tool_name = tool_call_obj[\"name\"]\n",
    "                    tool_args = tool_call_obj[\"args\"]\n",
    "                    tool_call_id = tool_call_obj[\"id\"]\n",
    "\n",
    "                    # execute the tool\n",
    "                    tool_out = name2tool[tool_name](**tool_args)\n",
    "\n",
    "                    # add the tool output to the agent scratchpad\n",
    "                    tool_exec = ToolMessage(\n",
    "                        content=f\"{tool_out}\", tool_call_id=tool_call_id\n",
    "                    )\n",
    "                    agent_scratchpad.append(tool_exec)\n",
    "\n",
    "                    # add a print so we can see intermediate steps\n",
    "                    print(f\"{count}: {tool_name}({tool_args}) -> {tool_out}\")\n",
    "\n",
    "                count += 1\n",
    "\n",
    "                # Check if any tool call is the final answer tool\n",
    "                if any(tc[\"name\"] == \"final_answer\" for tc in response.tool_calls):\n",
    "                    # Get the final answer from the final_answer tool\n",
    "                    final_tool_call = next(\n",
    "                        tc for tc in response.tool_calls if tc[\"name\"] == \"final_answer\"\n",
    "                    )\n",
    "                    final_answer = final_tool_call[\"args\"][\"answer\"]\n",
    "                    break\n",
    "            else:\n",
    "                # no tool call, we have a final answer\n",
    "                final_answer = response.content\n",
    "                break\n",
    "\n",
    "        # Add to conversation history ONLY the human input and final AI response\n",
    "        # This preserves memory without corrupting it with tool calls\n",
    "        self.memory.add_messages(\n",
    "            [HumanMessage(content=input), AIMessage(content=final_answer)]\n",
    "        )\n",
    "\n",
    "        # return the final answer in dict form\n",
    "        return {\"output\": final_answer}\n",
    "\n",
    "\n",
    "# Initialize the custom agent executor\n",
    "conversational_agent = CustomAgentExecutor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9e82479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: calculator({'expression': '10000 * (1 + 0.08)**5'}) -> 14693.280768000006\n",
      "1: final_answer({'answer': 'The value of 10000 * (1 + 0.08)**5 is approximately 14693.28.', 'tools_used': ['functions.calculator']}) -> {'answer': 'The value of 10000 * (1 + 0.08)**5 is approximately 14693.28.', 'tools_used': ['functions.calculator']}\n",
      "Result: The value of 10000 * (1 + 0.08)**5 is approximately 14693.28.\n"
     ]
    }
   ],
   "source": [
    "# First question\n",
    "result = conversational_agent.invoke(\"What is 10000 * (1 + 0.08)**5?\")\n",
    "print(f\"Result: {result['output']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-programs (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
